{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47802b3b",
   "metadata": {},
   "source": [
    "\n",
    "First, let's simulate some phenotypes (using your Phoenix data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6cb913ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import sksparse.cholmod\n",
    "import scipy.sparse\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "A=scipy.io.mmread(\"./A.mtx\")\n",
    "\n",
    "\n",
    "#Copy the population a few times to get more data\n",
    "A=scipy.sparse.block_diag((A,A)*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadf9ec4",
   "metadata": {},
   "source": [
    "Calculate the cholesky decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b4af5132",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_chol_obj=sksparse.cholmod.cholesky(A)\n",
    "P=scipy.sparse.identity(A.shape[0]).tocsc()[A_chol_obj.P()[:,np.newaxis],np.arange(A.shape[0])[np.newaxis,:]]\n",
    "A_chol=P.transpose()*A_chol_obj.L()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f43835",
   "metadata": {},
   "source": [
    "Check that I did this correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c15c3867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2.22044605e-16]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.max(A_chol*A_chol.transpose()-A,0),1).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ae005",
   "metadata": {},
   "source": [
    "Let's simulate 10 phenotypes with heritability=75%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a61e3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos=[\"NA\"]*10\n",
    "heritability=0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "3ad10204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    random.seed(10)\n",
    "    phenos[i]=A_chol*np.random.normal(size=A.shape[0])*np.sqrt(heritability)+scipy.sparse.identity(A.shape[0])*np.random.normal(size=A.shape[0])*np.sqrt(1-heritability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ba6fe",
   "metadata": {},
   "source": [
    "Shor T, et al. (2019) \"Estimating variance components in population scale family trees\" has a method for calculating the heritability of continuous traits. Let's see if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b33d1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HE(mat_list, y, MQS=False, verbose=False, sim_num=100, compute_stderr=False, y2=None):\n",
    "    # regress all covariates out of y\n",
    "    #CTC = cov.T.dot(cov)\n",
    "    y = y - np.mean(y)\n",
    "\n",
    "    # standardize y\n",
    "    y /= y.std()\n",
    "    # assert np.isclose(y.mean(), 0)\n",
    "    # assert np.isclose(y.var(), 1)\n",
    "    \n",
    "    if y2 is not None:\n",
    "        y2 -= cov.dot(np.linalg.solve(CTC, cov.T.dot(y2)))\n",
    "        y2 /= y2.std()\n",
    "        y = np.concatenate((y, y2))\n",
    "        \n",
    "        for m_i, m in enumerate(mat_list):\n",
    "            z = sparse.csr_matrix((m.shape[0], m.shape[0]))\n",
    "            mz = sparse.hstack([m,z])\n",
    "            zm = sparse.hstack([z,m])\n",
    "            mat_list[m_i] = sparse.vstack([zm, mz]).tocsr()\n",
    "            \n",
    "\n",
    "    # construct S and q, without MQS\n",
    "    K = len(mat_list)\n",
    "    n = y.shape[0]\n",
    "    if not MQS:\n",
    "        q = np.zeros(K)\n",
    "        S = np.zeros((K, K))\n",
    "        for i, mat_i in enumerate(mat_list):\n",
    "            if scipy.sparse.issparse(mat_i):\n",
    "                # q[i] = ((mat_i.multiply(y)).T.tocsr().dot(y)).sum() - mat_i.diagonal().dot(y**2)\n",
    "                q[i] = y.dot(mat_i.dot(y)) - mat_i.diagonal().dot(y ** 2)\n",
    "            else:\n",
    "                q[i] = ((mat_i * y).T.dot(y)).sum() - np.diag(mat_i).dot(y ** 2)\n",
    "            for j, mat_j in enumerate(mat_list):\n",
    "                if j > i: continue\n",
    "                if scipy.sparse.issparse(mat_i):\n",
    "                    S[i, j] = (mat_i.multiply(mat_j)).sum() - mat_i.diagonal().dot(mat_j.diagonal())\n",
    "                else:\n",
    "                    S[i, j] = np.einsum('ij,ij->', mat_i, mat_j) - np.diag(mat_i).dot(np.diag(mat_j))\n",
    "                S[j, i] = S[i, j]\n",
    "\n",
    "    # construct S and q with MQS (it's almost the same thing...)\n",
    "    else:        \n",
    "        q = np.zeros(K)\n",
    "        S = np.zeros((K, K))\n",
    "        for i, mat_i in enumerate(mat_list):\n",
    "            q[i] = (y.dot(mat_i.dot(y)) - y.dot(y))  # / float(n-1)**2\n",
    "            for j, mat_j in enumerate(mat_list):\n",
    "                if j > i: continue\n",
    "                S[i, j] = ((mat_i.multiply(mat_j)).sum() - (n - 1))  # / float(n-1)**2\n",
    "                S[j, i] = S[i, j]\n",
    "\n",
    "    # compute HE\n",
    "    he_est = np.linalg.solve(S, q)\n",
    "\n",
    "    if not compute_stderr:\n",
    "        return he_est\n",
    "\n",
    "    # compute H - the covariance matrix of y\n",
    "    H = mat_list[0] * he_est[0]\n",
    "    for mat_i, sigma2_i in zip(mat_list[1:], he_est[1:]):\n",
    "        H += mat_i * he_est[i]\n",
    "    H += scipy.sparse.eye(y.shape[0], format='csr') * (1.0 - he_est.sum())\n",
    "\n",
    "    # compute HE sampling variance\n",
    "    V_q = np.empty((K, K))\n",
    "    for i, mat_i in enumerate(mat_list):\n",
    "        if sim_num is None:\n",
    "            HAi_min_I = H.dot(mat_i) - H\n",
    "        for j, mat_i in enumerate(mat_list[:i + 1]):\n",
    "            if sim_num is None:\n",
    "                if j == i:\n",
    "                    HAj_min_I = HAi_min_I\n",
    "                else:\n",
    "                    HAj_min_I = H.dot(mat_j) - H\n",
    "                V_q[i, j] = 2 * (HAi_min_I.multiply(HAj_min_I)).sum()  # / float(n-1)**4\n",
    "            else:\n",
    "                # simulate vectors\n",
    "                sim_y = np.random.randn(n, sim_num)\n",
    "                Aj_minI_y = mat_j.dot(sim_y) - sim_y\n",
    "                H_Aj_minI_y = H.dot(Aj_minI_y)\n",
    "                Ai_min_I_H_Aj_minI_y = mat_i.dot(H_Aj_minI_y) - H_Aj_minI_y\n",
    "                H_Ai_min_I_H_Aj_minI_y = H.dot(Ai_min_I_H_Aj_minI_y)\n",
    "                V_q[i, j] = 2 * np.mean(np.einsum('ij,ij->j', sim_y, H_Ai_min_I_H_Aj_minI_y))\n",
    "\n",
    "            V_q[j, i] = V_q[i, j]\n",
    "    var_he_est = np.linalg.solve(S, np.linalg.solve(S, V_q).T).T\n",
    "\n",
    "    return he_est, np.sqrt(np.diag(var_he_est))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "30343c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "heritability_esti=['NA']*10\n",
    "for i,p in enumerate(phenos):\n",
    "    heritability_esti[i]=HE(mat_list=[A],y=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1e4ac8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7240552773742708"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(heritability_esti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4691c74",
   "metadata": {},
   "source": [
    "This number is pretty close to 75%. I've tested this method a lot, and it works pretty well, atleast if you have sufficient data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc089bf",
   "metadata": {},
   "source": [
    "But let's see what happens if we transform the data to binary traits (1% prevalence):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "91f11134",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=0.01\n",
    "phenos_binary=[(p>scipy.stats.norm.ppf(1-pre))*1.0 for p in phenos]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621eb05b",
   "metadata": {},
   "source": [
    "We use the conversion formula from Dempster and Lerner (1950):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1bf24de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "heritability_esti_binary=['NA']*10\n",
    "for i,p in enumerate(phenos_binary):\n",
    "    t=scipy.stats.norm.pdf(scipy.stats.norm.ppf(pre))\n",
    "    heritability_esti_binary[i]=HE(mat_list=[A],y=p)*pre*(1-pre)/t**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3ff6ea7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8707642630435948"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(heritability_esti_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e253d3",
   "metadata": {},
   "source": [
    "This result is totally off. You get a heritability well over 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217ee8da",
   "metadata": {},
   "source": [
    "In your article (Villemereuil et al. 2013; https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12011), you use a prevalence of 1/3, which seems to work a lot better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "45f68e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=1/3\n",
    "phenos_binary=[(p>scipy.stats.norm.ppf(1-pre))*1.0 for p in phenos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "287721db",
   "metadata": {},
   "outputs": [],
   "source": [
    "heritability_esti_binary=['NA']*10\n",
    "for i,p in enumerate(phenos_binary):\n",
    "    t=scipy.stats.norm.pdf(scipy.stats.norm.ppf(pre))\n",
    "    heritability_esti_binary[i]=HE(mat_list=[A],y=p)*pre*(1-pre)/t**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "42f61939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7389644844058678"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(heritability_esti_binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
